# working-with-LLMs

Notebooks for research on LLM capacities, including running autonomous LLMs locally *(Vicuna, GPT4all)* or using OpenAI ChatGPT API.

*Langchain_external_data_to_LLM.ipynb*      Exploring LangChain: some use cases how to connect external data to LLMs

*LLM_LoRA_finetuning_on_external_data.ipynb*        Training a Causal Language Model on external sensitive data using LoRA technique

*try_GPT4all_locally.ipynb*             Working with local LLMs of *GPT4All* family (using Python wrapper)  

*try_LLaMa_locally.ipynb*           Notebook Chat session with local LLM using llama.cpp engine

*try_LLaMa_locally.py*       Script for chating with local LLM using llama.cpp engine
