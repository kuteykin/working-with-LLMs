{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain: Use cases how to connect external data to LLMs\n",
    "### (see manual https://python.langchain.com/docs/ for more details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text colors\n",
    "green = \"\\033[0;32m\"\n",
    "white = \"\\033[0;39m\"\n",
    "cyan  = \"\\033[36m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_0 = \"\"\"\n",
    "You are a friendly chatbot assistant that responds in a conversational\n",
    "manner to users questions. Keep the answers short, unless specifically\n",
    "asked by the user to elaborate on something.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "prompt_0 = PromptTemplate(template=template_0, input_variables=[\"question\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local LLM *(e.g., GTP4all)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  ../Models/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "falcon_model_load: loading model from '../Models/ggml-model-gpt4all-falcon-q4_0.bin' - please wait ...\n",
      "falcon_model_load: n_vocab   = 65024\n",
      "falcon_model_load: n_embd    = 4544\n",
      "falcon_model_load: n_head    = 71\n",
      "falcon_model_load: n_head_kv = 1\n",
      "falcon_model_load: n_layer   = 32\n",
      "falcon_model_load: ftype     = 2\n",
      "falcon_model_load: qntvr     = 0\n",
      "falcon_model_load: ggml ctx size = 3872.64 MB\n",
      "falcon_model_load: memory_size =    32.00 MB, n_mem = 65536\n",
      "falcon_model_load: ........................ done\n",
      "falcon_model_load: model size =  3872.59 MB / num tensors = 196\n"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm_local = GPT4All(\n",
    "    model='../Models/ggml-model-gpt4all-falcon-q4_0.bin',\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The city of Paris was founded on May 24, 1252."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe city of Paris was founded on May 24, 1252.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_2 = input(\"Question? \")\n",
    "llm_local(question_2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote LLM via API call *(e.g., OpenAI )*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New approach for \"gpt-3.5-turbo\"and \"gpt-4\" models (using openai.ChatCompletion method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "# model_name = \"gpt-3.5-turbo\"\n",
    "model_name = \"gpt-4\"\n",
    "\n",
    "llm = ChatOpenAI(model_name=model_name, openai_api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Which language is used to create ChatGPT?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"ChatGPT is created using Python programming language. It's based on the GPT (Generative Pretrained Transformer) model developed by OpenAI. The model itself is trained on a variety of internet text, but when it comes to refining the model or 'fine-tuning' it, this is done using Python.\" additional_kwargs={} example=False\n",
      "\u001b[0;32mWhich language is used to create ChatGPT?\n",
      "\u001b[36mChatGPT: \u001b[0;39mChatGPT is created using Python programming language. It's based on the GPT (Generative Pretrained Transformer) model developed by OpenAI. The model itself is trained on a variety of internet text, but when it comes to refining the model or 'fine-tuning' it, this is done using Python.\n"
     ]
    }
   ],
   "source": [
    "response = llm([\n",
    "    SystemMessage(content=\"You are friendly AI assistant\"),\n",
    "    HumanMessage(content=query)\n",
    "])\n",
    "\n",
    "print(response)\n",
    "print(f\"{green}{query}\")\n",
    "print(f\"{cyan}ChatGPT: {white}{response.content}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a prompt template and running the LLM chain\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "template = \"What are the top {n} resources to learn {topic} ?\"\n",
    "prompt = PromptTemplate(template=template,input_variables=['n','topic'])\n",
    "\n",
    "input = {'n':3,'topic':'Python programming'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Codecademy: This is an online interactive platform that offers free coding classes in 12 different programming languages including Python. It's a great place for beginners as it provides an interactive learning environment where you can write code in the browser and see the result instantly.\n",
      "\n",
      "2. Coursera: Coursera offers a wide range of Python courses from top universities such as University of Michigan and Stanford. These courses cover everything from Python basics to data science and machine learning.\n",
      "\n",
      "3. Python.org: The official Python website has its own free learning resources and tutorials for beginners and advanced users. You can also find a list of other helpful resources, including books and other websites.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chain = LLMChain(llm=llm,prompt=prompt)\n",
    "print(chain.run(input))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_file = 'Input/books.db'\n",
    "db_uri = 'sqlite:///' + db_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup database\n",
    "\n",
    "from langchain.utilities import SQLDatabase\n",
    "db = SQLDatabase.from_uri(db_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup LLM\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=os.getenv('OPENAI_API_KEY'), temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the database chain\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "db_chain = SQLDatabaseChain.from_llm(llm=llm, db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Query template\n",
    "QUERY = \"\"\"\n",
    "Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return all requested  data in following format:\n",
    "\n",
    "QUESTION: Initial question here\n",
    "SQL QUERY: SQL Query to run\n",
    "SQL RESULT: Result of the SQLQuery execution\n",
    "ANSWER: Answer in natural language\n",
    "\n",
    "{question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate prompt\n",
    "def get_prompt():\n",
    "    '''Prompt-generation function, Receives a keyborad input, sends a request to LLM and returns an answer''' \n",
    "    \n",
    "    # Define text colors\n",
    "    green = \"\\033[0;32m\"\n",
    "    white = \"\\033[0;39m\"\n",
    "    cyan  = \"\\033[36m\"\n",
    "    print(\"Type 'exit' to quit\")\n",
    "\n",
    "    while True:\n",
    "        prompt = input(\"Enter a prompt: \")\n",
    "\n",
    "        if prompt.lower() == 'exit':\n",
    "            print('Exiting...')\n",
    "            break\n",
    "        else:\n",
    "            try:\n",
    "                question = QUERY.format(question=prompt)\n",
    "                print(f\"{green}{prompt}\")\n",
    "                print(f\"{cyan}ChatGPT: {white}{db_chain.run(question)}\")\n",
    "            except Exception as e:\n",
    "                print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'exit' to quit\n",
      "\u001b[0;32mHow many tables are in total?\n",
      "\u001b[36mChatGPT: \u001b[0;39mFinal answer here: There are 6 tables in total.\n",
      "\u001b[0;32mPlease return SQL query\n",
      "\u001b[36mChatGPT: \u001b[0;39mSQLQuery: SELECT * FROM Money LIMIT 5\n",
      "\u001b[0;32mincorrect. Try again\n",
      "\u001b[36mChatGPT: \u001b[0;39mincorrect. Try again\n",
      "\u001b[0;32mThink step by step\n",
      "\u001b[36mChatGPT: \u001b[0;39mSQLQuery: SELECT * FROM Money LIMIT 5;\n",
      "\u001b[0;32m\n",
      "\u001b[36mChatGPT: \u001b[0;39mSQLQuery: SELECT * FROM Money LIMIT 5;\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "get_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = \"Add new author 'Smith, John' to the position 12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Final answer here'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_chain.run(QUERY.format(question=prompt_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = \"List all the authors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'List all the authors'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final answer here: Paul Deitel, Harvey Deitel, Abbey Deitel\n"
     ]
    }
   ],
   "source": [
    "print(db_chain.run(QUERY.format(question=prompt_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect(db_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cursor object to execute SQL commands\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f163a9644c0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the tasks table if it doesn't exist\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS tasks\n",
    "             (id SERIAL PRIMARY KEY,\n",
    "             task TEXT NOT NULL,\n",
    "             completed BOOLEAN,\n",
    "             due_date DATE,\n",
    "             completion_date DATE,\n",
    "             priority INTEGER)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f163a9644c0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert sample tasks into the tasks table\n",
    "cursor.execute(\"INSERT INTO tasks (task, completed, due_date, completion_date, priority) VALUES ('Complete the web page design', True, '2023-05-01', '2023-05-03', 1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f163a9644c0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"INSERT INTO tasks (task, completed, due_date, completion_date, priority) VALUES ('Create login and signup pages', True, '2023-05-03', '2023-05-05', 2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f163a9644c0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"INSERT INTO tasks (task, completed, due_date, completion_date, priority) VALUES ('Product management', False, '2023-05-05', '2023-05-05', 3)\")\n",
    "cursor.execute(\"INSERT INTO tasks (task, completed, due_date, completion_date, priority) VALUES ('Cart and wishlist creation', False, '2023-05-08', '2023-05-05', 4)\")\n",
    "cursor.execute(\"INSERT INTO tasks (task, completed, due_date, completion_date, priority) VALUES  ('Payment gateway integration', False, '2023-05-10', '2023-05-05', 5)\")\n",
    "cursor.execute(\"INSERT INTO tasks (task, completed, due_date, completion_date, priority) VALUES ('Order management', False, '2023-05-10', '2023-05-05', 6)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Input a question: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How many tableas are in total?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'exit' to quit\n",
      "Final answer here: There are 6 tables in total.\n",
      "Final answer here: The tables in the database are 'sqlite_sequence', 'authors', 'titles', 'author_ISBN', 'tasks', and 'Money'.\n",
      "Final answer here: The only table in the database with a corresponding entry in the sqlite_sequence table is the \"authors\" table, with a value of 12.\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "get_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
